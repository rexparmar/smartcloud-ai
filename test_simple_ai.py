#!/usr/bin/env python3
"""
Simple test script for AI capabilities without heavy dependencies
This script tests the basic AI functionality without requiring transformers/torch.
"""

import os
import sys
import logging
from dotenv import load_dotenv

# Add the app directory to the Python path
sys.path.append(os.path.join(os.path.dirname(__file__), 'app'))

# Load environment variables
load_dotenv()

# Set up logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

def test_simple_ai():
    """Test simple AI functionality"""
    print("ü§ñ Testing Simple AI System")
    print("=" * 50)
    
    # Sample document content
    sample_content = """
    SmartCloud AI Platform - Technical Documentation
    
    The SmartCloud AI Platform is a comprehensive document management and AI analysis system designed to help users organize, analyze, and extract insights from their files. The platform combines advanced AI capabilities with intuitive user interfaces to provide powerful document processing features.
    
    Key Features:
    - Intelligent file tagging and categorization
    - AI-powered document summarization
    - Natural language querying of document content
    - Multi-format file support (PDF, DOCX, TXT, etc.)
    - Secure file storage and sharing capabilities
    - Real-time AI processing with background tasks
    
    Technical Architecture:
    The system is built using FastAPI for the backend API, SQLAlchemy for database management, and Celery for background task processing. The AI components utilize multiple providers including OpenAI GPT models, Hugging Face transformers, and local rule-based fallbacks for maximum reliability.
    
    Current Status:
    The platform is currently in active development with core features implemented and tested. The AI processing pipeline supports multiple providers with automatic fallback mechanisms to ensure consistent service availability.
    
    Future Plans:
    Planned enhancements include advanced document comparison, collaborative editing features, and expanded AI model support. The team is also working on performance optimizations and additional file format support.
    """
    
    try:
        # Import AI components
        from app.ai.simple_ai_client import get_simple_ai_client
        from app.ai.openai_client import get_openai_client
        
        # Test Simple AI Client
        print("üìù Testing Simple AI Client")
        print("-" * 30)
        
        simple_client = get_simple_ai_client()
        
        # Test 1: Generate Summary
        print("üìÑ Testing Document Summarization")
        summary_result = simple_client.generate_summary(sample_content)
        
        if summary_result["status"] == "success":
            print(f"‚úÖ Summary generated successfully using {summary_result.get('model', 'unknown')}")
            print(f"üìÑ Summary: {summary_result['summary']}")
        else:
            print(f"‚ùå Summary generation failed: {summary_result.get('message', 'Unknown error')}")
        print()
        
        # Test 2: Generate Tags
        print("üè∑Ô∏è Testing Document Tagging")
        tags_result = simple_client.generate_tags(sample_content)
        
        if tags_result["status"] == "success":
            print(f"‚úÖ Tags generated successfully using {tags_result.get('model', 'unknown')}")
            print(f"üè∑Ô∏è Tags: {', '.join(tags_result['tags'])}")
        else:
            print(f"‚ùå Tag generation failed: {tags_result.get('message', 'Unknown error')}")
        print()
        
        # Test 3: Query Document
        print("‚ùì Testing Document Querying")
        print("-" * 30)
        
        test_questions = [
            "What are the key features of this platform?",
            "What is the current status of the project?",
            "What are the future plans mentioned?",
            "What technologies are used in this system?"
        ]
        
        for question in test_questions:
            print(f"ü§î Question: {question}")
            query_result = simple_client.query_file_content(sample_content, question)
            
            if query_result["status"] == "success":
                print(f"‚úÖ Answer (using {query_result.get('model', 'unknown')}): {query_result['answer']}")
            else:
                print(f"‚ùå Query failed: {query_result.get('message', 'Unknown error')}")
            print()
        
        # Test OpenAI Client (if available)
        print("üîç Testing OpenAI Client")
        print("-" * 30)
        
        openai_client = get_openai_client()
        if openai_client.is_available():
            print("‚úÖ OpenAI API is configured")
            
            # Test OpenAI summary
            openai_summary = openai_client.generate_summary(sample_content)
            if openai_summary["status"] == "success":
                print(f"‚úÖ OpenAI summary: {openai_summary['summary'][:100]}...")
            else:
                print(f"‚ùå OpenAI summary failed: {openai_summary.get('message', 'Unknown error')}")
        else:
            print("‚ö†Ô∏è OpenAI API not configured (set OPENAI_API_KEY environment variable)")
        
        print()
        
        # Test 4: Enhanced Processor
        print("üîÑ Testing Enhanced Processor")
        print("-" * 30)
        
        try:
            from app.ai.enhanced_processor import get_enhanced_processor
            
            processor = get_enhanced_processor()
            
            # Test complete processing
            complete_result = processor.process_file_complete(sample_content)
            
            if complete_result["status"] == "success":
                print(f"‚úÖ Complete processing successful")
                print(f"üìÑ Summary: {complete_result['summary'][:100]}...")
                print(f"üè∑Ô∏è Tags: {', '.join(complete_result['tags'])}")
                print(f"üìä Analysis: {complete_result.get('analysis', {})}")
            else:
                print(f"‚ùå Complete processing failed: {complete_result.get('message', 'Unknown error')}")
                
        except Exception as e:
            print(f"‚ùå Enhanced processor test failed: {e}")
        
        print()
        
    except ImportError as e:
        print(f"‚ùå Import error: {e}")
        print("Make sure you're running this from the project root directory")
    except Exception as e:
        print(f"‚ùå Error during testing: {e}")
        logger.error(f"Test error: {e}")

def test_environment_setup():
    """Test environment setup and API keys"""
    print("üîß Environment Setup Check")
    print("=" * 50)
    
    # Check environment variables
    env_vars = {
        "OPENAI_API_KEY": os.getenv("OPENAI_API_KEY"),
        "HUGGINGFACE_API_KEY": os.getenv("HUGGINGFACE_API_KEY"),
    }
    
    print("Environment Variables:")
    for var, value in env_vars.items():
        if value:
            print(f"  ‚úÖ {var}: {'*' * 10} (set)")
        else:
            print(f"  ‚ùå {var}: Not set")
    
    print("\nRecommendations:")
    if not env_vars["OPENAI_API_KEY"]:
        print("  - Set OPENAI_API_KEY for GPT-3.5/4 access (paid)")
    
    if not env_vars["HUGGINGFACE_API_KEY"]:
        print("  - Set HUGGINGFACE_API_KEY for free API access")
    
    print("  - Simple AI client works without any API keys")
    print("  - Rule-based fallback is always available")

if __name__ == "__main__":
    print("üöÄ SmartCloud Simple AI System Test")
    print("=" * 60)
    print()
    
    # Test environment setup
    test_environment_setup()
    print()
    
    # Test AI functionality
    test_simple_ai()
    
    print("‚úÖ Testing completed!")
    print("\nüí° Tips:")
    print("- Simple AI client works without heavy dependencies")
    print("- Set OPENAI_API_KEY for best AI performance")
    print("- Set HUGGINGFACE_API_KEY for free AI alternatives")
    print("- The system automatically falls back to rule-based processing") 